{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regresison models for \n",
    "\n",
    "### model ①\n",
    "\n",
    "metric_level gained =  function(FLcumulativecompetence, interact_classmates, metric_Gender, motivationdegree, voterank, out_degree_weighted, degree_weighted, betweenness_weighted)\n",
    "\n",
    "### model ② \n",
    "\n",
    "metric_level gained =  function(FLcumulativecompetence, interact_classmates, metric_Gender, motivationdegree + tylko te miary centralności, których kontrybucja w powyższym jest istotna (przedział ufności nie zawiera 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_type = \"tl123_edges\"\n",
    "df_merged = pd.DataFrame()\n",
    "\n",
    "\n",
    "for i in range(1, 4, 1):\n",
    "    eda_path = Path(f\"analysis/{network_type}/{i}_eda.csv\")\n",
    "    eda = pd.read_csv(eda_path, index_col=0)\n",
    "    print(len(eda), len(eda.columns))\n",
    "    df_merged = pd.concat([df_merged, eda], ignore_index=True)\n",
    "\n",
    "print(len(df_merged), len(df_merged.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select columns to be used in regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_df = df_merged[\n",
    "    [\n",
    "        \"metric_level gained\",\n",
    "        \"metric_FLcumulativecompetence\",\n",
    "        \"interact_classmates\",\n",
    "        \"metric_Gender\",\n",
    "        \"psycho_motivationdegree\",\n",
    "\n",
    "        #     \"betweenness_weighted\",\n",
    "        # \"betweenness\",\n",
    "        # \"in_degree_weighted\",\n",
    "        # \"in_degree\",\n",
    "        # \"out_degree_weighted\",\n",
    "        # \"out_degree\",\n",
    "        # \"degree_weighted\",\n",
    "        # \"degree\",\n",
    "        \"pagerank_weighhted\",\n",
    "        # 'pagerank',\n",
    "        \"closeness\",\n",
    "        # \"voterank\",\n",
    "        #    \"clustering_coefficient\",\n",
    "    ]\n",
    "]\n",
    "\n",
    "reg_df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean up data (convert strings to floats, fill NaNs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_with_nans = []\n",
    "for col in reg_df.columns:\n",
    "    if reg_df[col].isnull().values.any():\n",
    "        print(col, reg_df[col].unique())\n",
    "        cols_with_nans.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_df = reg_df.fillna({col: 0 for col in cols_with_nans})\n",
    "reg_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_df[\"metric_Gender\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_df[\"gender\"] = reg_df[\"metric_Gender\"].apply(lambda x: 0. if x == \"female\" else 1.)\n",
    "reg_df[\"metric_Gender\"] = reg_df[\"gender\"]\n",
    "reg_df = reg_df.drop([\"gender\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_df.hist()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nreg_df=(reg_df-reg_df.min())/(reg_df.max()-reg_df.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nreg_df.hist()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/27928275/find-p-value-significance-in-scikit-learn-linearregression\n",
    "# https://medium.com/swlh/interpreting-linear-regression-through-statsmodels-summary-4796d359035a\n",
    "\n",
    "X = nreg_df.drop([\"metric_level gained\"], axis=1)\n",
    "y = nreg_df[\"metric_level gained\"]\n",
    "\n",
    "X2 = sm.add_constant(X)\n",
    "est = sm.OLS(y, X2)\n",
    "est2 = est.fit()\n",
    "print(est2.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"regression_with_interception.csv\", \"w\") as file:\n",
    "    file.write(est2.summary().as_csv())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mldev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
