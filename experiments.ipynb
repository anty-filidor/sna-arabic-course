{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_path = \"data/whitby_01_00_byu_Jordan_23.csv\"\n",
    "\n",
    "with open(df_path) as f:\n",
    "    _cols = f.readline()[1:-2]\n",
    "_cols = _cols.split('\",\"')\n",
    "dtype_mapper = {c: str for c in _cols if (\"net@\" in c and \"choice\" not in c)}\n",
    "\n",
    "df = pd.read_csv(df_path, converters = dtype_mapper)\n",
    "df = df.drop(df.loc[df[\"group_questionnaire_order\"] != 1].index)\n",
    "df = df.set_index(\"metric_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_ego_cols = {col for col in df.columns if (\"net\" in col and \"choice\" in col)}\n",
    "edge_course_cols = {col for col in df.columns if \"net\" in col}.difference(edge_ego_cols)\n",
    "node_cols = set(df.columns).difference(edge_course_cols).difference(edge_ego_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_ego_df = df[list(edge_ego_cols)]\n",
    "edge_course_df = df[list(edge_course_cols)]\n",
    "node_df = df[list(node_cols)]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtain weighted adjacency matrix for ego network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 nan net@3rdchoice\n",
      "3 nan net@2ndchoice\n",
      "3 nan net@5thchoice\n",
      "3 nan net@1stchoice\n",
      "3 nan net@4thchoice\n",
      "8 nan net@5thchoice\n",
      "10 nan net@5thchoice\n",
      "16 nan net@5thchoice\n",
      "16 nan net@4thchoice\n",
      "20 nan net@5thchoice\n",
      "20 nan net@4thchoice\n",
      "21 nan net@5thchoice\n",
      "21 nan net@4thchoice\n",
      "23 nan net@5thchoice\n",
      "25 nan net@5thchoice\n",
      "26 nan net@5thchoice\n",
      "30 nan net@5thchoice\n",
      "30 nan net@4thchoice\n",
      "31 nan net@5thchoice\n",
      "36 nan net@5thchoice\n",
      "38 nan net@5thchoice\n",
      "38 nan net@4thchoice\n",
      "41 nan net@5thchoice\n",
      "41 nan net@4thchoice\n"
     ]
    }
   ],
   "source": [
    "ego_edge_list = []\n",
    "\n",
    "for node, row in edge_ego_df.iterrows():\n",
    "    for choice_level, choice_node in row.items():\n",
    "        try:\n",
    "            weight = int(choice_level[4])  # e.g. net@2ndchoice -> 2\n",
    "            choice_node = int(choice_node)\n",
    "            ego_edge_list.append({\"source\": node, \"target\": choice_node, \"weight\": weight})\n",
    "        except:\n",
    "            print(node, choice_node, choice_level)\n",
    "\n",
    "pd.DataFrame(ego_edge_list).to_csv(\"ego_edge_list.csv\")  # TODO: RENAME!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtain weighted edge list for course network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_edge(code: str) -> dict:\n",
    "\n",
    "    if len(code) != 3:\n",
    "        print(code)\n",
    "        return {}\n",
    "    try:\n",
    "        int(code)\n",
    "    except:\n",
    "        print(code)\n",
    "        return {}\n",
    "    \n",
    "    if code[0] == \"1\":\n",
    "        direction = \"out\"\n",
    "    elif code[0] == \"2\":\n",
    "        direction = \"in\"\n",
    "    elif code[0] == \"3\":\n",
    "        direction = \"mutual\"\n",
    "    else:\n",
    "        print(code)\n",
    "        return {}\n",
    "    intensity = int(code[1]) / 5  # normalised\n",
    "    lang_usage = int(code[2]) / 9  # normalised\n",
    "\n",
    "    return {\"direction\": direction, \"intensity\": intensity, \"lang_usage\": lang_usage}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x?\n",
      "self\n",
      "?\n",
      "x2x\n",
      "xxx\n",
      "xxx\n",
      "xxx\n",
      "xxx\n",
      "self\n",
      "xxx\n",
      "xxx\n",
      "xxx\n",
      "xxx\n",
      "self\n",
      "xxx\n",
      "xxx\n",
      "xxx\n",
      "self\n",
      "xxx\n",
      "xxx\n",
      "xxx\n",
      "xxx\n",
      "xxx\n",
      "xxx\n",
      "xxx\n",
      "xxx\n",
      "xxx\n",
      "xxx\n",
      "xxx\n",
      "xxx\n",
      "xxx\n",
      "xxx\n",
      "xxx\n",
      "xxx\n",
      "xxx\n",
      "self\n",
      "xxx\n",
      "xxx\n",
      "x20\n",
      "xxx\n",
      "xxx\n",
      "xxx\n",
      "self\n",
      "xxx\n",
      "xxx\n",
      "xxx\n",
      "23x\n",
      "self\n",
      "13x\n",
      "xxx\n",
      "x10\n",
      "self\n",
      "xxx\n",
      "xxx\n",
      "xxx\n",
      "x10\n",
      ".320\n",
      "x10\n",
      "x30\n",
      "x10\n",
      "x10\n",
      "xxx\n",
      "xxx\n",
      "xxx\n",
      "self\n",
      "x52\n",
      "self\n",
      "xxx\n",
      "xxx\n",
      "xxx\n",
      "xxx\n",
      "xxx\n",
      "xxx\n",
      "xxx\n",
      "xxx\n",
      "xxx\n",
      "xxx\n",
      "030\n",
      "xxx\n",
      "xxx\n",
      "xxx\n",
      "xxx\n",
      "self\n",
      "xxx\n",
      "xxx\n",
      "xxx\n",
      "self\n",
      "xxx\n",
      "xxx\n",
      "xxx\n",
      "xxx\n",
      "xxx\n",
      "xxx\n",
      "self\n",
      "xxx\n",
      "xxx\n",
      "xxx\n",
      "xxx\n",
      "xxx\n",
      "xxx\n",
      "xxx\n",
      "xxx\n",
      "xxx\n",
      "x27\n",
      "xxx\n",
      "xxx\n",
      "self\n",
      "xxx\n",
      "xxx\n",
      "xxx\n",
      "xxx\n",
      "xxx\n",
      "xxx\n",
      "xxx\n",
      "xxx\n",
      "xxx\n",
      "xxx\n",
      "xxx\n",
      "x23\n",
      "xxx\n",
      "xxx\n",
      "xxx\n",
      "self\n",
      "xxx\n",
      "xxx\n",
      "xxx\n",
      "self\n",
      "xxx\n",
      "self\n",
      "xxx\n",
      "xxx\n",
      "xxx\n",
      "xxx\n",
      "xxx\n",
      "xxx\n",
      "xxx\n",
      "xxx\n",
      "xxx\n",
      "self\n",
      "xxx\n",
      "xxx\n",
      "self\n",
      "xxx\n",
      "x20\n",
      "x10\n",
      "xxx\n",
      "xxx\n",
      "self\n",
      "x10\n",
      "x10\n",
      "x33\n",
      "xxx\n",
      "x10\n",
      "x22\n",
      "xxx\n",
      "xxx\n",
      "x10\n",
      "xxx\n",
      "xxx\n",
      "x10\n",
      "x10\n",
      "x10\n",
      "xxx\n",
      "x10\n",
      "xxx\n",
      "xxx\n",
      "x10\n",
      "xxx\n",
      "x22\n",
      "x10\n",
      "xxx\n",
      "self\n",
      "self\n",
      "x20\n",
      "030\n",
      "x52\n",
      "xxx\n",
      "x10\n",
      "x10\n",
      "selt\n",
      "xxx\n",
      "x43\n",
      "x20\n",
      "x21\n",
      "022\n",
      "xxx\n",
      "x10\n",
      "xxx\n",
      "self\n",
      "xxx\n",
      "xxx\n",
      "xxx\n",
      "xxx\n",
      "x10\n",
      "xxx\n",
      "xxx\n",
      "xxx\n",
      "xxx\n",
      "x30\n",
      "self\n",
      "xxx\n",
      "xxx\n",
      "xxx\n",
      "xxx\n",
      "x20\n",
      "xxx\n",
      "x10\n",
      "xxx\n",
      "x20\n",
      "xxx\n",
      "xxx\n",
      "xxx\n",
      "xxx\n",
      "self\n",
      "x52\n",
      "xxx\n",
      "xxx\n",
      "xxx\n",
      "xxx\n",
      "xxx\n",
      "x52\n",
      "xxx\n",
      "xxx\n",
      "x52\n",
      "x10\n",
      "xxx\n",
      "xxx\n",
      "xxx\n",
      "xxx\n",
      "x37\n",
      "xxx\n",
      "x37\n",
      "x37\n",
      "xxx\n",
      "xxx\n",
      "xxx\n",
      "xxx\n",
      "x37\n",
      "xxx\n",
      "x10\n",
      "xxx\n",
      "x32\n",
      "self\n",
      "xxx\n",
      "xxx\n",
      "x37\n",
      "xxx\n",
      "xxx\n",
      "x10\n",
      "x32\n",
      "x10\n",
      "xxx\n",
      "xxx\n",
      "xxx\n",
      "xxx\n",
      "xxx\n",
      "xxx\n",
      "xxx\n",
      "xxx\n",
      "xxx\n",
      "self\n",
      "xxx\n",
      "xxx\n",
      "1130\n",
      "xxx\n",
      "xxx\n",
      "xxx\n",
      "xxx\n",
      "xxx\n",
      "xxx\n",
      "xxx\n",
      "xxx\n",
      "xxx\n",
      "xxx\n",
      "xxx\n",
      "xxx\n",
      "xxx\n",
      "xxx\n",
      "xxx\n",
      "xxx\n",
      "xxx\n",
      "xxx\n",
      "xxx\n",
      "xxx\n",
      "xxx\n",
      "xxx\n",
      "self\n",
      "xx2\n",
      "x00\n",
      "x00\n",
      "x00\n",
      "x00\n",
      "x00\n",
      "x00\n",
      "x00\n",
      "x00\n",
      "self\n",
      "x23\n",
      "x11\n",
      "x00\n",
      "x00\n",
      "x00\n",
      "x00\n",
      "x00\n",
      "x00\n",
      "x00\n",
      "self\n",
      "x00\n",
      "x00\n",
      "x00\n",
      "x00\n",
      "x00\n",
      "x00\n",
      "x00\n",
      "x00\n",
      "x00\n",
      "x00\n",
      "x00\n",
      "x00\n",
      "x00\n",
      "x00\n",
      "x00\n",
      "x00\n",
      "x00\n",
      "x00\n",
      "x00\n",
      "x00\n",
      "x00\n",
      "x00\n",
      "x00\n",
      "x00\n",
      "x00\n",
      "x00\n",
      "x00\n",
      "x00\n",
      "self\n",
      "self\n",
      "x00\n",
      "x00\n",
      "x00\n",
      "x00\n",
      "x00\n",
      "x00\n",
      "x00\n",
      "x00\n",
      "x00\n",
      "x00\n",
      "x00\n",
      "x00\n",
      "x00\n",
      "x00\n",
      "x10\n",
      "x00\n",
      "x00\n",
      "x00\n",
      "x00\n",
      "x10\n",
      "x00\n",
      "x00\n",
      "x00\n",
      "x00\n",
      "x00\n",
      "x00\n",
      "x00\n",
      "self\n",
      "x00\n",
      "x00\n",
      "x00\n",
      "x00\n",
      "x45\n",
      "x00\n",
      "x00\n",
      "x00\n",
      "x00\n",
      "x00\n",
      "x00\n",
      "x00\n",
      "x00\n",
      "x00\n",
      "x00\n",
      "x00\n",
      "self\n"
     ]
    }
   ],
   "source": [
    "course_edge_list = []\n",
    "\n",
    "for source_node, row in edge_course_df.iterrows():\n",
    "    for target_node, code in row.items():\n",
    "        decoded_edge = decode_edge(str(code))\n",
    "        if len(decoded_edge) == 0:\n",
    "            continue\n",
    "        course_edge_list.append({\"source\": source_node, \"target\": int(target_node[4:]), **decoded_edge})\n",
    "\n",
    "pd.DataFrame(course_edge_list).to_csv(\"course_edge_list.csv\")  # TODO: RENAME!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtain node list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removing 36 columns\n"
     ]
    }
   ],
   "source": [
    "# remove columns that don't add any information, i.e. each node has the same value for these columns\n",
    "\n",
    "garbage_attrs = []\n",
    "for col in node_df.columns:\n",
    "    unique_vals = node_df[col].unique()\n",
    "    if len(unique_vals) == 1:\n",
    "        garbage_attrs.append(col)\n",
    "\n",
    "print(f\"removing {len(garbage_attrs)} columns\")\n",
    "node_df = node_df.drop(garbage_attrs, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_df = node_df.reset_index().rename({\"metric_id\": \"node_id\"}, axis=1)\n",
    "node_df.to_csv(\"node_list.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mldev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
